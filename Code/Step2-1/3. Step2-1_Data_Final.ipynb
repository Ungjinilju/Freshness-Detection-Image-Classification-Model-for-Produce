{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd880851",
   "metadata": {},
   "source": [
    "# Guide\n",
    "실행 불필요  \n",
    "전처리 완료된 데이터 링크 아래 참고\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40ebc1",
   "metadata": {},
   "source": [
    "# Data\n",
    "[[Google Drive] /Data/Final/Step2-1.zip](https://drive.google.com/file/d/1KjVfu9UgvK0_tZtuOcJmaRCn44CtYxUq/view?usp=sharing)\n",
    "\n",
    "## Dataset Source\n",
    "- [[Kaggle] Fruit and Vegetable Disease (Healthy vs Rotten)](https://www.kaggle.com/datasets/muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten)  \n",
    "apple, banana, orange 데이터만 사용  \n",
    "- [[Roboflow] apples Computer Vision Project](https://universe.roboflow.com/ds-lxa2d/apples-daz2v)  \n",
    "프로젝트에 사용된 데이터 사용 : apple\n",
    "\n",
    "## Preprocessing\n",
    "- Kaggle  \n",
    "기존 데이터셋에는 이미 증강 이미지 존재(일부 클래스에만) → 다른 Step의 모델에도 사용하기 위해 증강 이미지 삭제 + 중복 이미지 삭제 \n",
    "- Roboflow  \n",
    "fresh, rotten으로 나누어진 이미지 중 모델 학습에 적합하다고 판단되는 데이터만 사용 + 중복 이미지 삭제\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c84421",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "- ### 데이터의 다양성 확보\n",
    "기존 데이터는 하나의 사과에 대해 여러 각도에서 찍은 여러 이미지 존재  \n",
    "이 데이터를 증강시켜 사용  \n",
    "⇒ 유사한 데이터가 많아 모델이 좀 더 일반적인 특성을 학습하기 어렵다고 판단  \n",
    "- ### 각 클래스 별 데이터 불균형 해소\n",
    "각 클래스 별 데이터 수 상이  \n",
    "- ### 증강 누락 이미지 처리\n",
    "1개의 이미지 당 2개의 증강 이미지 생성했으나 전체 데이터 수가 이전 데이터 수의 정확히 3배가 되지 않음  \n",
    "증강 이미지의 파일명이 중복되어 일부 데이터 누락\n",
    "\n",
    "\n",
    "# Difference\n",
    "- Roboflow의 데이터 추가(apple)  \n",
    "Step1에서 추가한 데이터 사용\n",
    "- 데이터 랜덤 언더샘플링  \n",
    "- 증강 이미지 파일명 : `f'aug_{filename.split(\".\")[0]}'` → `f'aug_{filename.split(\".\")[0]}_{str(uuid.uuid4())}'`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbab850",
   "metadata": {},
   "source": [
    "# Data Random Undersampling\n",
    "## Data\n",
    "|              |&nbsp;&nbsp;&nbsp;Original&nbsp;&nbsp;&nbsp;| Remove |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Result&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|\n",
    "|:------------:|:------------:|:------------:|:------------:|\n",
    "| Apple_Fresh  | 460 | 160 | 300 |\n",
    "| Apple_Rotten | 460 | 160 | 300 | \n",
    "| Banana_Fresh | 433 | 133 | 300 |\n",
    "| Banana_Rotten | 539 | 239 | 300 |\n",
    "| Orange_Fresh | 406 | 106 | 300 |\n",
    "| Orange_Rotten | 422 | 122 | 300 |\n",
    "\n",
    "\n",
    "Step2-2에서도 동일한 데이터를 사용하기 위해 데이터가 가장 적은 Pomegranate_Rotten의 수(300)로 언더샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171294bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b04f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_undersampling(directory):\n",
    "\n",
    "    image_files = [f for f in os.listdir(directory) if f.endswith((\".jpg\", \".png\"))]\n",
    "    \n",
    "    delete_count = len(image_files) - 300\n",
    "\n",
    "    # 삭제할 파일 랜덤 선택\n",
    "    files_to_delete = random.sample(image_files, delete_count)\n",
    "\n",
    "    # 삭제된 파일 수\n",
    "    count = 0\n",
    "\n",
    "    # 파일 삭제\n",
    "    for file_name in files_to_delete:\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        os.remove(file_path)\n",
    "    \n",
    "        count += 1\n",
    "    \n",
    "    print(f\"deleted images: {count}\")\n",
    "    print(f\"current images: {len([f for f in os.listdir(directory) if f.endswith(('.jpg', '.png'))])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63b6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/tf/Fixed_Data/Data_Final/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2272a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple_Fresh\n",
      "deleted images: 160\n",
      "current images: 300\n",
      "Apple_Rotten\n",
      "deleted images: 160\n",
      "current images: 300\n"
     ]
    }
   ],
   "source": [
    "# Apple_Fresh\n",
    "print(\"Apple_Fresh\")\n",
    "dir = os.path.join(base_dir, 'apple_300/fresh')\n",
    "random_undersampling(dir)\n",
    "\n",
    "# Apple_Rotten\n",
    "print(\"Apple_Rotten\")\n",
    "dir = os.path.join(base_dir, 'apple_300/stale')\n",
    "random_undersampling(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71032628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banana_Fresh\n",
      "deleted images: 133\n",
      "current images: 300\n",
      "Banana_Rotten\n",
      "deleted images: 238\n",
      "current images: 300\n"
     ]
    }
   ],
   "source": [
    "# Banana_Fresh\n",
    "print(\"Banana_Fresh\")\n",
    "dir = os.path.join(base_dir, 'banana/fresh')\n",
    "random_undersampling(dir)\n",
    "\n",
    "# Banana_Rotten\n",
    "print(\"Banana_Rotten\")\n",
    "dir = os.path.join(base_dir, 'banana/stale')\n",
    "random_undersampling(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe41913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orange_Fresh\n",
      "deleted images: 106\n",
      "current images: 300\n",
      "Orange_Rotten\n",
      "deleted images: 122\n",
      "current images: 300\n"
     ]
    }
   ],
   "source": [
    "# Orange_Fresh\n",
    "print(\"Orange_Fresh\")\n",
    "dir = os.path.join(base_dir, 'orange/fresh')\n",
    "random_undersampling(dir)\n",
    "\n",
    "# Orange_Rotten\n",
    "print(\"Orange_Rotten\")\n",
    "dir = os.path.join(base_dir, 'orange/stale')\n",
    "random_undersampling(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ce688",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "`ImageDataGenerator` 사용\n",
    "\n",
    "## Augmentation Ratio\n",
    "1개의 이미지 당 2개의 증강 이미지 생성\n",
    "\n",
    "## Data\n",
    "|              |&nbsp;&nbsp;&nbsp;Original&nbsp;&nbsp;&nbsp;| Augmentation |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Final&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|\n",
    "|:------------:|:------------:|:------------:|:------------:|\n",
    "| Apple_Fresh  | 300 | 600 | 900 |\n",
    "| Apple_Rotten | 300 | 600 | 900 |\n",
    "| Banana_Fresh | 300 | 600 | 900 |\n",
    "| Banana_Rotten | 300 | 600 | 900 |\n",
    "| Orange_Fresh | 300 | 600 | 900 |\n",
    "| Orange_Rotten | 300 | 600 | 900 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f3d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 15:13:56.111369: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import numpy as np\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d6725ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=90,            # 회전 각도 범위 [-90, +90]\n",
    "    shear_range=0.3,              # 전단 변형(층밀림) 각도 [0, 0.3](radian):최대 약 17도\n",
    "    zoom_range=[0.7, 1.3],        # 확대/축소 범위. 원본의 70% ~ 130%\n",
    "    brightness_range=[0.2, 1.3],  # 밝기 조정 범위. 원본의 20% ~ 130%\n",
    "    horizontal_flip=True,         # 좌우 반전\n",
    "    vertical_flip=True,           # 상하 반전\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a4a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(input_dir, output_dir):\n",
    "    \n",
    "    for filename in os.listdir(input_dir):\n",
    "        \n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            \n",
    "            img_path = os.path.join(input_dir, filename)\n",
    "            img = load_img(img_path)  # 이미지 로드\n",
    "            x = img_to_array(img)     # numpy 배열로 변환\n",
    "            x = np.expand_dims(x, axis=0)  # 배치 차원 추가\n",
    "            \n",
    "            # 원본 이미지 저장\n",
    "            original_output_path = os.path.join(output_dir, f'original_{filename}')\n",
    "            img.save(original_output_path)  # 원본 이미지 저장\n",
    "        \n",
    "            # 증강 이미지 생성 및 저장\n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, batch_size=1, save_to_dir=output_dir, save_prefix=f'aug_{filename.split(\".\")[0]}_{str(uuid.uuid4())}', save_format='jpg'):\n",
    "                i += 1\n",
    "                if i >= 2:  # 하나의 이미지당 2개의 증강 이미지\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d2e3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/tf/Fixed_Data/Data_Final/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7801193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple_Fresh\n",
    "input_dir = os.path.join(base_dir, 'apple_300/fresh')\n",
    "output_dir = os.path.join(base_dir, 'Step2/Apple_Fresh')\n",
    "\n",
    "data_augmentation(input_dir, output_dir)\n",
    "\n",
    "\n",
    "# Apple_Rotten\n",
    "input_dir = os.path.join(base_dir, 'apple_300/stale')\n",
    "output_dir = os.path.join(base_dir, 'Step2/Apple_Rotten')\n",
    "\n",
    "data_augmentation(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3da37234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banana_Fresh\n",
    "input_dir = os.path.join(base_dir, 'banana/fresh')\n",
    "output_dir = os.path.join(base_dir, 'Step2/Banana_Fresh')\n",
    "\n",
    "data_augmentation(input_dir, output_dir)\n",
    "\n",
    "\n",
    "# Banana_Rotten\n",
    "input_dir = os.path.join(base_dir, 'banana/stale')\n",
    "output_dir = os.path.join(base_dir, 'Step2/Banana_Rotten')\n",
    "\n",
    "data_augmentation(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d1e5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orange_Fresh\n",
    "input_dir = os.path.join(base_dir, 'orange/fresh')\n",
    "output_dir = os.path.join(base_dir, 'Step2/Orange_Fresh')\n",
    "\n",
    "data_augmentation(input_dir, output_dir)\n",
    "\n",
    "\n",
    "# Orange_Rotten\n",
    "input_dir = os.path.join(base_dir, 'orange/stale')\n",
    "output_dir = os.path.join(base_dir, 'Step2/Orange_Rotten')\n",
    "\n",
    "data_augmentation(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198768a",
   "metadata": {},
   "source": [
    "# Data Split\n",
    "## Original and Augmented Data\n",
    "/tf/Fixed_Data/Data_Final/Data/Step2  \n",
    "│  \n",
    "├── Apple_Fresh  \n",
    "│  \n",
    "├── Apple_Rotten  \n",
    "│  \n",
    "├── Banana_Fresh  \n",
    "│  \n",
    "├── Banana_Rotten  \n",
    "│  \n",
    "├── Orange_Fresh  \n",
    "│  \n",
    "└── Orange_Rotten  \n",
    "\n",
    "## Splited Data\n",
    "/tf/Fixed_Data/Data_Final/Step2   \n",
    "│  \n",
    "├── train  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Apple_Fresh  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Apple_Rotten  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Banana_Fresh  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Banana_Rotten  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Orange_Fresh  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── Orange_Rotten  \n",
    "│  \n",
    "├── validation  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Apple_Fresh  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Apple_Rotten  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Banana_Fresh  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Banana_Rotten  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Orange_Fresh  \n",
    "│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── Orange_Rotten   \n",
    "│  \n",
    "└── test  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Apple_Fresh  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Apple_Rotten  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Banana_Fresh  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Banana_Rotten  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── Orange_Fresh  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── Orange_Rotten  \n",
    "\n",
    "    \n",
    "## Split Ratio\n",
    "train : validation : test = 7 : 2 : 1\n",
    "\n",
    "## Dataset\n",
    "|              | &nbsp;&nbsp;&nbsp; train &nbsp;&nbsp;&nbsp; | validation | &nbsp;&nbsp;&nbsp;&nbsp; test &nbsp;&nbsp;&nbsp;&nbsp; |\n",
    "|:------------:|:------------:|:------------:|:------------:|\n",
    "| Apple_Fresh  | 630 | 180 | 90 |\n",
    "| Apple_Rotten | 630 | 180 | 90 |\n",
    "| Banana_Fresh  | 630 | 180 | 90 |\n",
    "| Banana_Rotten | 630 | 180 | 90 |\n",
    "| Orange_Fresh  | 630 | 180 | 90 |\n",
    "| Orange_Rotten | 630 | 180 | 90 |\n",
    "| Total | 3780 | 1080 | 540 |\n",
    "\n",
    "## Code\n",
    "교재 Chapter 8-2 서브셋 저장 코드 참고\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e48c364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ad9e54",
   "metadata": {},
   "source": [
    "### Source : 교재 코드 8-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5f0315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 리스트를 서브셋으로 저장\n",
    "def make_subset(subset_name, file_list):\n",
    "    \n",
    "    for file_path, category in file_list:\n",
    "        \n",
    "        dst_dir = os.path.join(new_base_dir, subset_name, category)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        shutil.copy(file_path, os.path.join(dst_dir, os.path.basename(file_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "945339f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 비율로 데이터 분할 후 서브셋 생성\n",
    "def split_data(base_dir, train_ratio, val_ratio):\n",
    "    \n",
    "    # 클래스 디렉토리 수집\n",
    "    class_dirs = [d for d in os.listdir(base_dir) \n",
    "                  if os.path.isdir(os.path.join(base_dir, d)) and not d.startswith('.')]\n",
    "    \n",
    "    train_data = 0\n",
    "    val_data = 0\n",
    "    test_data = 0\n",
    "    \n",
    "    # 데이터 분할\n",
    "    for class_dir in class_dirs:\n",
    "        \n",
    "        class_path = os.path.join(base_dir, class_dir)\n",
    "        \n",
    "        # 파일 목록 수집\n",
    "        files = [(os.path.join(class_path, f), class_dir) \n",
    "                 for f in os.listdir(class_path) if not f.startswith('.')]\n",
    "        \n",
    "        # 데이터 shuffle\n",
    "        random.shuffle(files)\n",
    "\n",
    "        # 데이터 분할\n",
    "        total = len(files)\n",
    "        train_index = int(total * train_ratio)\n",
    "        val_index = train_index + int(total * val_ratio)\n",
    "\n",
    "        train_files = files[:train_index]\n",
    "        val_files = files[train_index:val_index]\n",
    "        test_files = files[val_index:]\n",
    "\n",
    "        # 서브셋 생성\n",
    "        make_subset(\"train\", train_files)\n",
    "        make_subset(\"validation\", val_files)\n",
    "        make_subset(\"test\", test_files)\n",
    "        \n",
    "        train_data += len(train_files)\n",
    "        val_data += len(val_files)\n",
    "        test_data += len(test_files)\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4575e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = \"/tf/Fixed_Data/Data_Final/Data/Step2\"\n",
    "new_base_dir = \"/tf/Fixed_Data/Data_Final/Step2-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5e6c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train:validation:test = 7:2:1\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b0e9912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 3780, Validation files: 1080, Test files: 540\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할 및 서브셋 생성\n",
    "train_count, val_count, test_count = split_data(original_dir, train_ratio, val_ratio)\n",
    "\n",
    "print(f\"Train files: {train_count}, Validation files: {val_count}, Test files: {test_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
